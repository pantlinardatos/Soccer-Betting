{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Months With Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK,Trials\n",
    "from sklearn.cross_validation import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DATASET IMPORT\n",
    "df=pd.read_csv('ExportTrainingWithoutMonthsAndLowOdds17.csv',low_memory=False)\n",
    "df=df.dropna (axis=0, how=\"any\")\n",
    "#Choose the features\n",
    "X=df[[\"PureProbaHome\",\"PureProbaAway\",\n",
    "               'RelativePointsDifference',\n",
    "              'RelativeSumTeamGoals','RelativeEatSumTeamGoals']]\n",
    "y=df[['FullTimeResultID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_train_test(params):\n",
    "    X_ = X[:]\n",
    "\n",
    "    if 'normalize' in params:\n",
    "        if params['normalize'] == 1:\n",
    "            X_ = normalize(X_)\n",
    "        del params['normalize']\n",
    "\n",
    "    if 'scale' in params:\n",
    "        if params['scale'] == 1:\n",
    "            X_ = scale(X_)\n",
    "        del params['scale']\n",
    "    #clf = LogisticRegression(**params)\n",
    "    #clf = RandomForestClassifier(**params)\n",
    "    #clf = DecisionTreeClassifier(**params)\n",
    "    clf = KNeighborsClassifier(**params)\n",
    "        \n",
    "    cv=KFold(X_.shape[0],5,shuffle=True,random_state=5)\n",
    "    return cross_val_score(clf, X_, y.values.ravel(),cv=cv).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "def f(params):\n",
    "    global best\n",
    "    acc = hyperopt_train_test(params)\n",
    "    if acc > best:\n",
    "        best = acc\n",
    "        print 'new best:', best, params\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Logistic4space = {\n",
    "    'C': hp.uniform('C', 0, 20),     \n",
    "    'penalty': hp.choice('penalty', ['l2']),\n",
    "    'scale': hp.choice('scale', [0, 1]),\n",
    "    'normalize': hp.choice('normalize', [0, 1]),\n",
    "    'intercept_scaling': hp.uniform('intercept_scaling', 0, 10),\n",
    "    'solver': hp.choice('solver', ['lbfgs','liblinear','sag', 'newton-cg']),\n",
    "    'class_weight': hp.choice('class_weight', ['balanced',None]), \n",
    "    'max_iter': hp.quniform('max_iter',1,100000,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Forest4space = {\n",
    "    'n_estimators': hp.choice('n_estimators', [5,10,15,20,100]),\n",
    "    'criterion': hp.choice('criterion', ['gini','entropy']),\n",
    "    'max_depth': hp.quniform('max_depth',1,20,1),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),     \n",
    "    'class_weight': hp.choice('class_weight', ['balanced',None]), \n",
    "    'oob_score': hp.choice('oob_score', [True,False]),\n",
    "    'verbose': hp.quniform('verbose',1,100,1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Desicion4space = {\n",
    "    'criterion': hp.choice('criterion', ['gini','entropy']),\n",
    "    'max_depth': hp.quniform('max_depth',1,20,1),\n",
    "    'min_weight_fraction_leaf': hp.uniform('min_weight_fraction_leaf', 0, 0.5),     \n",
    "    'class_weight': hp.choice('class_weight', ['balanced',None])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Neighbour4space = {\n",
    "    'n_neighbors': hp.quniform('n_neighbors',1,1000,1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters = [ 'C','penalty','scale', 'normalize', 'intercept_scaling', 'solver','class_weight','max_iter']\n",
    "#parameters = [ 'n_estimators','criterion','max_depth', 'min_weight_fraction_leaf', 'class_weight', 'oob_score','verbose']\n",
    "#parameters = [ 'criterion','max_depth', 'min_weight_fraction_leaf', 'class_weight']\n",
    "parameters = [ 'n_neighbors','algorithm', 'leaf_size', 'weights',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the comments and the space for other algorithm optimistation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 0.429891304348 {'n_neighbors': 970.0}\n",
      "new best: 0.434433229814 {'n_neighbors': 249.0}\n",
      "new best: 0.448395445135 {'n_neighbors': 37.0}\n",
      "best:\n",
      "{'n_neighbors': 37.0}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f, Neighbour4space , algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "print 'best:'\n",
    "print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.Beep(300,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'algorithm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-f0e6b8a8cd2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'misc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vals'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'result'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'algorithm'"
     ]
    }
   ],
   "source": [
    "cols = len(parameters)\n",
    "f, axes = plt.subplots(nrows=1, ncols=cols, figsize=(20,5))\n",
    "cmap = plt.cm.jet\n",
    "for i, val in enumerate(parameters):\n",
    "    xs = np.array([t['misc']['vals'][val] for t in trials.trials]).ravel()\n",
    "    ys = [-t['result']['loss'] for t in trials.trials]\n",
    "  \n",
    "    axes[i].scatter(xs, ys, s=20, linewidth=0.01, alpha=0.25, c=cmap(float(i)/len(parameters)))\n",
    "    axes[i].set_title(val)\n",
    "    axes[i].set_ylim([0.6, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without Months,with all odds\n",
    "\n",
    "#### LogisticRegression\n",
    "clf=LogisticRegression(multi_class='multinomial',C=0.4594858284186373,intercept_scaling =0.6601243488037598,max_iter= 69573.0,class_weight=None,solver='lbfgs')\n",
    "#### Random Forest\n",
    "clf2=RandomForestClassifier(oob_score=True,verbose=70.0, n_estimators= 20, min_weight_fraction_leaf= 0.0005073465668121592, criterion='entropy', max_depth= 18.0, class_weight=None)\n",
    "#### Desicion Tree\n",
    "clf3=DecisionTreeClassifier(min_weight_fraction_leaf= 9.098497062798826e-05, criterion = 'entropy', max_depth = 19.0, class_weight= None)\n",
    "#### Nearest Neigbour \n",
    "clf4=KNeighborsClassifier(n_neighbors=41)\n",
    "\n",
    "# Without Months, and without low odds < 1.5\n",
    "\n",
    "#### LogisticRegression\n",
    "clf=LogisticRegression(C =5.843931905064714, intercept_scaling =0.8571990171497501, solver = 'sag', max_iter = 94813.0, penalty ='l2', class_weight= None)\n",
    "#### Random Forest\n",
    "clf2=RandomForestClassifier(oob_score= True, verbose= 88.0, n_estimators= 15 , min_weight_fraction_leaf =0.000133536321622163, criterion='entropy' , max_depth = 17.0, class_weight = None)\n",
    "#### Desicion Tree\n",
    "clf3=DecisionTreeClassifier(min_weight_fraction_leaf= 0.10375200619153369, criterion ='entropy', max_depth= 15.0, class_weight=None)\n",
    "#### Nearest Neigbour \n",
    "clf4=KNeighborsClassifier(n_neighbors=47)\n",
    "# Without Months, and without low odds <= 1.7\n",
    "\n",
    "#### LogisticRegression\n",
    "clf=LogisticRegression(C= 8.054656300305119, intercept_scaling = 1.5481631052682, solver ='newton-cg', max_iter = 538.0, penalty= 'l2', class_weight= None)\n",
    "#### Random Forest\n",
    "clf2=RandomForestClassifier(oob_score= True, verbose= 79.0, n_estimators= 5 , min_weight_fraction_leaf =0.05272839386424666, criterion='entropy' , max_depth = 17.0, class_weight = None)\n",
    "#### Desicion Tree\n",
    "clf3=DecisionTreeClassifier(min_weight_fraction_leaf= 0.03003518945237782, criterion= 'gini', max_depth =15.0, class_weight= None)\n",
    "#### Nearest Neigbour \n",
    "clf4=KNeighborsClassifier(n_neighbors=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
